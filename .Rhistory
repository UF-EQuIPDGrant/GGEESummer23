View(Q1results)
View(Q1results)
remove_words <-data.frame("word"= c("coded", "program", "6th", "5th", "3rd", "4th", "7th", "0","1","10","
1st", "27","null", "NA", "na", "coding", "ive", "that's", "code", "grade", "2", "
2015", "2021", "2022", "30", "3rd", "50", "6", "9", "90", "experience", "learned", "called", "candy"))
Q1Srestidy<-unnest_tokens(Q1Omit, word, Experience_Type)
Q1Sres_remove<- anti_join(Q1Srestidy,remove_words) #remove repeat words
Q1Sresclean<-anti_join(Q1Sres_remove, stop_words)
Q1Sres_counts <- count(Q1Sresclean, word, sort = TRUE)
Q1results <- filter(Q1Sres_counts, n > 1)
wordcloud2(Q1results)
remove_words <-data.frame("word"= c("coded", "program", "6th", "5th", "3rd", "4th", "7th", "0","1","10","
1st", "27","null", "NA", "na", "coding", "ive", "that's", "code", "grade", "2", "
2015", "2021", "2022", "30", "3rd", "50", "6", "9", "90", "experience", "learned", "called", "candy", "chapman"))
Q1Srestidy<-unnest_tokens(Q1Omit, word, Experience_Type)
Q1Sres_remove<- anti_join(Q1Srestidy,remove_words) #remove repeat words
Q1Sresclean<-anti_join(Q1Sres_remove, stop_words)
Q1Sres_counts <- count(Q1Sresclean, word, sort = TRUE)
Q1results <- filter(Q1Sres_counts, n > 1)
wordcloud2(Q1results)
remove_words <-data.frame("word"= c("coded", "program", "6th", "5th", "3rd", "4th", "7th", "0","1","10","
1st", "27","null", "NA", "na", "coding", "ive", "that's", "code", "grade", "2", "
2015", "2021", "2022", "30", "3rd", "50", "6", "9", "90", "experience", "learned", "called", "candy", "chapman", "forgot", "floor", "lake", "taught", "parents", "taking", "stuff", "simple", "east"))
Q1Srestidy<-unnest_tokens(Q1Omit, word, Experience_Type)
Q1Sres_remove<- anti_join(Q1Srestidy,remove_words) #remove repeat words
Q1Sresclean<-anti_join(Q1Sres_remove, stop_words)
Q1Sres_counts <- count(Q1Sresclean, word, sort = TRUE)
Q1results <- filter(Q1Sres_counts, n > 1)
wordcloud2(Q1results)
wordcloud(words = d$word,
freq = d$freq,
scale = c(8,.3),
random.order = F,
random.color = F,
colors = pal)
wordcloud(words = Q1results$word,
freq = Q1results$freq,
scale = c(8,.3),
random.order = F,
random.color = F,
colors = pal)
wordcloud2(words = Q1results$word,
freq = Q1results$freq,
scale = c(8,.3),
random.order = F,
random.color = F,
colors = pal)
wordcloud2(data=Q1results, size=1.5)
wordcloud2(data=Q1results)
wordcloud2(data=Q1results, color=brewer.pal(9,"Blues"))
wordcloud2(data=Q1results, color=Blues)
wordcloud2(data=Q1results, color='Blues')
wordcloud2(data=Q1results, color='Blue')
wordcloud2(data=Q1results, color='random-blue')
wordcloud2(data=Q1results, color='random-light')
wordcloud2(data=Q1results, color='random-dark')
library(RColorBrewer)
color_range_number <- length(unique(Q1results$word))
color <- colorRampPalette(brewer.pal(9,"Blues")[3:7])(color_range_number)[factor(Q1results$word)]
wordcloud2(Q1results, color=color)
hw <-wordcloud2(Q1results, color=color)
#hw <- wordcloud2(Q1results,size = 3)
saveWidget(hw,"1.html",selfcontained = F)
webshot::webshot("1.html","1.png",vwidth = 1992, vheight = 1744, delay =10)
webshot::webshot("1.html","1.png",vwidth = 1992, vheight = 1744, delay =5)
webshot::webshot("1.html","1.png",vwidth = 1800, vheight = 1200, delay =10)
hw <-wordcloud2(Q1results, color=color, size=2)
#hw <- wordcloud2(Q1results,size = 3)
saveWidget(hw,"1.html",selfcontained = F)
webshot::webshot("1.html","1.png",vwidth = 1800, vheight = 1200, delay =10)
Q1results %>%
filter(n > 5) %>% # keep rows with word counts greater than 500
mutate(word = reorder(word, n)) %>% #reorder the word variable by n and replace with new variable called word
ggplot(aes(n, word)) + # create a plot with n on x axis and word on y axis
geom_col()+ # make it a bar plot
geom_bar(position= position_dodge(),stat="identity", fill= "#9ECAE2", colour='black', size=.3) +
theme_classic()+
theme(axis.text.x = element_text(colour = "black"))+
theme(axis.text.y = element_text(colour = "black"))+
ggtitle("GGEE Summer 2023 Student Prior Experience")+
theme(plot.title = element_text(hjust = 0.5))+
scale_x_continuous(expand = c(0, 0), limits = c(0, 30), n.breaks=5)+
xlab("Count")+
ylab("Words")
ggsave(
filename = "GGEE_23_Summer_Prior_Experience_Graph.png",
plot = last_plot(),
device = "png",
path = "/Users/kristadulany/Documents/GitHub/GGEESummer23/Graphs/Pre_Survey Responses",
scale = 2,
width = 6,
height = 4,
units = c("in"),
dpi = 300,
limitsize = TRUE,
bg = NULL)
Q1results %>%
filter(n > 5) %>% # keep rows with word counts greater than 500
mutate(word = reorder(word, n)) %>% #reorder the word variable by n and replace with new variable called word
ggplot(aes(n, word)) + # create a plot with n on x axis and word on y axis
geom_col()+ # make it a bar plot
geom_bar(position= position_dodge(),stat="identity", fill= "#9ECAE2", colour='black', size=.3) +
theme_classic()+
theme(axis.text.x = element_text(colour = "black"))+
theme(axis.text.y = element_text(colour = "black"))+
ggtitle("GGEE Summer 2023 Student Prior Experience")+
theme(plot.title = element_text(hjust = 0.5))+
scale_x_continuous(expand = c(0, 0), limits = c(0, 30), n.breaks=10)+
xlab("Count")+
ylab("Words")
ggsave(
filename = "GGEE_23_Summer_Prior_Experience_Graph.png",
plot = last_plot(),
device = "png",
path = "/Users/kristadulany/Documents/GitHub/GGEESummer23/Graphs/Pre_Survey Responses",
scale = 2,
width = 6,
height = 4,
units = c("in"),
dpi = 300,
limitsize = TRUE,
bg = NULL)
remove_words <-data.frame("word"= c("coded", "program", "6th", "5th", "3rd", "4th", "7th", "0","1","10","
1st", "27","null", "NA", "na", "coding", "ive", "that's", "code", "grade", "2", "
2015", "2021", "2022", "30", "3rd", "50", "6", "9", "90", "experience", "learned", "called", "candy", "chapman", "forgot", "floor", "lake", "taught", "parents", "taking", "stuff", "simple", "east", "hart"))
Q1Sres <- read_excel("Data/GGEE_23_PreSurvey.xlsx", sheet = 1)
Q1SresSel<- select(Q1Sres, Response_ID, Experience_Type)
Q1Omit <- na.omit(Q1SresSel)
#no remove words
Q1Srestidy<-unnest_tokens(Q1Omit, word, Experience_Type)
Q1Sresclean<-anti_join(Q1Srestidy, stop_words)
Q1Sres_counts <- count(Q1Sresclean, word, sort = TRUE)
wordcloud2(Q1Sres_counts)
remove_words <-data.frame("word"= c("coded", "program", "6th", "5th", "3rd", "4th", "7th", "0","1","10","
1st", "27","null", "NA", "na", "coding", "ive", "that's", "code", "grade", "2", "
2015", "2021", "2022", "30", "3rd", "50", "6", "9", "90", "experience", "learned", "called", "candy", "chapman", "forgot", "floor", "lake", "taught", "parents", "taking", "stuff", "simple", "east", "hart"))
Q1Srestidy<-unnest_tokens(Q1Omit, word, Experience_Type)
---
#title: Pre Survey Analysis
#author: Krista Dulany Chisholm
#date: August 31, 2023
---
#Load Libraries
library(tidyverse)
library(tidyr)
library(writexl)
library(readxl)
library(textdata)
library(ggplot2)
library(scales)
library(ggrepel)
library(wordcloud2)
library(htmlwidgets)
install.packages("webshot")
webshot::install_phantomjs()
Q1Sres <- read_excel("Data/GGEE_23_PreSurvey.xlsx", sheet = 1)
Q1SresSel<- select(Q1Sres, Response_ID, Experience_Type)
Q1Omit <- na.omit(Q1SresSel)
#no remove words
Q1Srestidy<-unnest_tokens(Q1Omit, word, Experience_Type)
Q1Sresclean<-anti_join(Q1Srestidy, stop_words)
Q1Sres_counts <- count(Q1Sresclean, word, sort = TRUE)
wordcloud2(Q1Sres_counts)
remove_words <-data.frame("word"= c("coded", "program", "6th", "5th", "3rd", "4th", "7th", "0","1","10","
1st", "27","null", "NA", "na", "coding", "ive", "that's", "code", "grade", "2", "
2015", "2021", "2022", "30", "3rd", "50", "6", "9", "90", "experience", "learned", "called", "candy", "chapman", "forgot", "floor", "lake", "taught", "parents", "taking", "stuff", "simple", "east", "hart"))
Q1Srestidy<-unnest_tokens(Q1Omit, word, Experience_Type)
Q1Sres_remove<- anti_join(Q1Srestidy,remove_words) #remove repeat words
Q1Sresclean<-anti_join(Q1Sres_remove, stop_words)
Q1Sres_counts <- count(Q1Sresclean, word, sort = TRUE)
Q1results <- filter(Q1Sres_counts, n > 1)
Q1Sres <- read_excel("Data/GGEE_23_PreSurvey.xlsx", sheet = 1)
Q1SresSel<- select(Q1Sres, Response_ID, Experience_Type)
Q1Omit <- na.omit(Q1SresSel)
remove_words <-data.frame("word"= c("coded", "program", "6th", "5th", "3rd", "4th", "7th", "0","1","10","
1st", "27","null", "NA", "na", "coding", "ive", "that's", "code", "grade", "2", "
2015", "2021", "2022", "30", "3rd", "50", "6", "9", "90", "experience", "learned", "called", "candy", "chapman", "forgot", "floor", "lake", "taught", "parents", "taking", "stuff", "simple", "east", "hart"))
Q1Srestidy<-unnest_tokens(Q1Omit, word, Experience_Type)
Q1Sres_remove<- anti_join(Q1Srestidy,remove_words) #remove repeat words
Q1Sresclean<-anti_join(Q1Sres_remove, stop_words)
Q1Sres_counts <- count(Q1Sresclean, word, sort = TRUE)
---
#title: Pre Survey Analysis
#author: Krista Dulany Chisholm
#date: August 31, 2023
---
#Load Libraries
library(tidyverse)
library(tidytext)
library(dplyr)
library(readr)
library(tidyr)
library(writexl)
library(readxl)
library(textdata)
library(ggplot2)
library(scales)
library(ggrepel)
library(wordcloud2)
library(htmlwidgets)
Q1Sres <- read_excel("Data/GGEE_23_PreSurvey.xlsx", sheet = 1)
Q1SresSel<- select(Q1Sres, Response_ID, Experience_Type)
Q1Omit <- na.omit(Q1SresSel)
remove_words <-data.frame("word"= c("coded", "program", "6th", "5th", "3rd", "4th", "7th", "0","1","10","
1st", "27","null", "NA", "na", "coding", "ive", "that's", "code", "grade", "2", "
2015", "2021", "2022", "30", "3rd", "50", "6", "9", "90", "experience", "learned", "called", "candy", "chapman", "forgot", "floor", "lake", "taught", "parents", "taking", "stuff", "simple", "east", "hart"))
Q1Srestidy<-unnest_tokens(Q1Omit, word, Experience_Type)
Q1Sres_remove<- anti_join(Q1Srestidy,remove_words) #remove repeat words
Q1Sresclean<-anti_join(Q1Sres_remove, stop_words)
Q1Sres_counts <- count(Q1Sresclean, word, sort = TRUE)
Q1results <- filter(Q1Sres_counts, n > 1)
library(RColorBrewer)
color_range_number <- length(unique(Q1results$word))
color <- colorRampPalette(brewer.pal(9,"Blues")[3:7])(color_range_number)[factor(Q1results$word)]
hw <-wordcloud2(Q1results, color=color, size=2)
#hw <- wordcloud2(Q1results,size = 3)
saveWidget(hw,"1.html",selfcontained = F)
webshot::webshot("1.html","1.png",vwidth = 1800, vheight = 1200, delay =10)
---
#title: Pre Survey Analysis
#author: Krista Dulany Chisholm
#date: August 31, 2023
---
#Load Libraries
library(tidyverse)
library(tidyr)
library(writexl)
library(readxl)
library(textdata)
library(ggplot2)
library(scales)
library(ggrepel)
library(wordcloud2)
library(htmlwidgets)
install.packages("webshot")
webshot::install_phantomjs()
---
#title: Pre Survey Analysis
#author: Krista Dulany Chisholm
#date: August 31, 2023
---
#Load Libraries
library(tidyverse)
library(tidytext)
library(dplyr)
library(readr)
library(tidyr)
library(writexl)
library(readxl)
library(textdata)
library(ggplot2)
library(scales)
library(ggrepel)
library(wordcloud2)
library(htmlwidgets)
library(webshot)
Q1Sres <- read_excel("Data/GGEE_23_PreSurvey.xlsx", sheet = 1)
Q1SresSel<- select(Q1Sres, Response_ID, Experience_Type)
Q1Omit <- na.omit(Q1SresSel)
remove_words <-data.frame("word"= c("coded", "program", "6th", "5th", "3rd", "4th", "7th", "0","1","10","
1st", "27","null", "NA", "na", "coding", "ive", "that's", "code", "grade", "2", "
2015", "2021", "2022", "30", "3rd", "50", "6", "9", "90", "experience", "learned", "called", "candy", "chapman", "forgot", "floor", "lake", "taught", "parents", "taking", "stuff", "simple", "east", "hart"))
Q1Srestidy<-unnest_tokens(Q1Omit, word, Experience_Type)
Q1Sres_remove<- anti_join(Q1Srestidy,remove_words) #remove repeat words
Q1Sresclean<-anti_join(Q1Sres_remove, stop_words)
Q1Sres_counts <- count(Q1Sresclean, word, sort = TRUE)
Q1results <- filter(Q1Sres_counts, n > 1)
hw <-wordcloud2(Q1results, color=color, size=2)
library(RColorBrewer)
color_range_number <- length(unique(Q1results$word))
color <- colorRampPalette(brewer.pal(9,"Blues")[3:7])(color_range_number)[factor(Q1results$word)]
hw <-wordcloud2(Q1results, color=color, size=2)
hw
Q1Sres <- read_excel("Data/GGEE_23_PreSurvey.xlsx", sheet = 1)
Q1SresSel<- select(Q1Sres, Response_ID, Experience_Type)
Q1Omit <- na.omit(Q1SresSel)
Q1Sresclean<-anti_join(Q1Sres_remove, stop_words)
library(hunspell)
library(purrr)
correct_spelling <- function(Q1Sresclean) {
output <- case_when(
# any manual corrections
input == 'license' ~ 'licence',
# check and (if required) correct spelling
!hunspell_check(input, dictionary('en_GB')) ~
hunspell_suggest(input, dictionary('en_GB')) %>%
# get first suggestion, or NA if suggestions list is empty
map(1, .default = NA) %>%
unlist(),
TRUE ~ input # if word is correct
)
# if input incorrectly spelled but no suggestions, return input word
ifelse(is.na(Q1Sresclean), Q1Sresclean, Q1Sresclean)
}
Q1Sresclean<-anti_join(Q1Sres_remove, stop_words)
library(hunspell)
library(purrr)
correct_spelling <- function(Q1Sresclean) {
output <- case_when(
# any manual corrections
input == 'license' ~ 'licence',
# check and (if required) correct spelling
!hunspell_check(input, dictionary('en_GB')) ~
hunspell_suggest(input, dictionary('en_GB')) %>%
# get first suggestion, or NA if suggestions list is empty
map(1, .default = NA) %>%
unlist(),
TRUE ~ input # if word is correct
)
# if input incorrectly spelled but no suggestions, return input word
ifelse(is.na(Q1Sresclean2), Q1Sresclean, Q1Sresclean2)
}
View(Q1Sres_counts)
Q1Sres <- read_excel("Data/GGEE_23_PreSurvey.xlsx", sheet = 1)
Q1SresSel<- select(Q1Sres, Response_ID, Experience_Type)
Q1Omit <- na.omit(Q1SresSel)
remove_words <-data.frame("word"= c("coded", "program", "6th", "5th", "3rd", "4th", "7th", "0","1","10","
1st", "27","null", "NA", "na", "coding", "ive", "that's", "code", "grade", "2", "
2015", "2021", "2022", "30", "3rd", "50", "6", "9", "90", "experience", "learned", "called", "candy", "chapman", "forgot", "floor", "lake", "taught", "parents", "taking", "stuff", "simple", "east", "hart"))
Q1Srestidy<-unnest_tokens(Q1Omit, word, Experience_Type)
Q1Sres_remove<- anti_join(Q1Srestidy,remove_words) #remove repeat words
Q1Sresclean<-anti_join(Q1Sres_remove, stop_words)
library(hunspell)
library(purrr)
correct_spelling <- function(input) {
output <- case_when(
# any manual corrections
input == 'license' ~ 'licence',
# check and (if required) correct spelling
!hunspell_check(input, dictionary('en_GB')) ~
hunspell_suggest(input, dictionary('en_GB')) %>%
# get first suggestion, or NA if suggestions list is empty
map(1, .default = NA) %>%
unlist(),
TRUE ~ input # if word is correct
)
# if input incorrectly spelled but no suggestions, return input word
ifelse(is.na(output), input, output) }
View(correct_spelling)
Q1Sres <- read_excel("Data/GGEE_23_PreSurvey.xlsx", sheet = 1)
Q1SresSel<- select(Q1Sres, Response_ID, Experience_Type)
Q1Omit <- na.omit(Q1SresSel)
##Make correct spelling function
library(hunspell)
library(purrr)
correct_spelling <- function(input) {
output <- case_when(
# any manual corrections
input == 'license' ~ 'licence',
# check and (if required) correct spelling
!hunspell_check(input, dictionary('en_GB')) ~
hunspell_suggest(input, dictionary('en_GB')) %>%
# get first suggestion, or NA if suggestions list is empty
map(1, .default = NA) %>%
unlist(),
TRUE ~ input # if word is correct
)
# if input incorrectly spelled but no suggestions, return input word
ifelse(is.na(output), input, output) }
Q1Sres_counts <- Q1Sresclean %>%
rename(original = word) %>%
group_by(original) %>%
summarise(count = n()) %>%
ungroup() %>% # so we can mutate word
mutate(suggestion = correct_spelling(original)) %>%
filter(suggestion != original)
######################################################################################
#remove words
remove_words <-data.frame("word"= c("coded", "program", "6th", "5th", "3rd", "4th", "7th", "0","1","10","
1st", "27","null", "NA", "na", "coding", "ive", "that's", "code", "grade", "2", "
2015", "2021", "2022", "30", "3rd", "50", "6", "9", "90", "experience", "learned", "called", "candy", "chapman", "forgot", "floor", "lake", "taught", "parents", "taking", "stuff", "simple", "east", "hart"))
Q1Srestidy<-unnest_tokens(Q1Omit, word, Experience_Type)
Q1Sres_remove<- anti_join(Q1Srestidy,remove_words) #remove repeat words
Q1Sresclean<-anti_join(Q1Sres_remove, stop_words)
Q1Sres_counts <- Q1Sresclean %>%
rename(original = word) %>%
group_by(original) %>%
summarise(count = n()) %>%
ungroup() %>% # so we can mutate word
mutate(suggestion = correct_spelling(original)) %>%
filter(suggestion != original)
######################################################################################
#remove words
remove_words <-data.frame("word"= c("coded", "program", "6th", "5th", "3rd", "4th", "7th", "0","1","10","
1st", "27","null", "NA", "na", "coding", "ive", "that's", "code", "grade", "2", "
2015", "2021", "2022", "30", "3rd", "50", "6", "9", "90", "experience", "learned", "called", "candy", "chapman", "forgot", "floor", "lake", "taught", "parents", "taking", "stuff", "simple", "east", "hart"))
Q1Srestidy<-unnest_tokens(Q1Omit, word, Experience_Type, to_lower = FALSE)
Q1Sres_remove<- anti_join(Q1Srestidy,remove_words) #remove repeat words
Q1Sresclean<-anti_join(Q1Sres_remove, stop_words)
Q1Sres_counts <- Q1Sresclean %>%
rename(original = word) %>%
group_by(original) %>%
summarise(count = n()) %>%
ungroup() %>% # so we can mutate word
mutate(suggestion = correct_spelling(original)) %>%
filter(suggestion != original)
######################################################################################
#remove words
remove_words <-data.frame("word"= c("coded", "program", "6th", "5th", "3rd", "4th", "7th", "0","1","10","
1st", "27","null", "NA", "na", "coding", "ive", "that's", "code", "grade", "2", "
2015", "2021", "2022", "30", "3rd", "50", "6", "9", "90", "experience", "learned", "called", "candy", "chapman", "forgot", "floor", "lake", "taught", "parents", "taking", "stuff", "simple", "east", "hart"))
Q1Srestidy<-unnest_tokens(Q1Omit, word, Experience_Type, to_lower = FALSE)
Q1Sres_remove<- anti_join(Q1Srestidy,remove_words) #remove repeat words
Q1Sresclean<-anti_join(Q1Sres_remove, stop_words)
Q1Sres_counts <- Q1Sresclean %>%
rename(original = Q1Sresclean) %>%
group_by(original) %>%
summarise(count = n()) %>%
ungroup() %>% # so we can mutate word
mutate(suggestion = correct_spelling(original)) %>%
filter(suggestion != original)
rlang::last_trace()
Q1Sresclean2 %>% select(all_of(Q1Sresclean))
Q1Sresclean %>% select(all_of(Q1Sresclean))
data
######################################################################################
#remove words
remove_words <-data.frame("word"= c("coded", "program", "6th", "5th", "3rd", "4th", "7th", "0","1","10","
1st", "27","null", "NA", "na", "coding", "ive", "that's", "code", "grade", "2", "
2015", "2021", "2022", "30", "3rd", "50", "6", "9", "90", "experience", "learned", "called", "candy", "chapman", "forgot", "floor", "lake", "taught", "parents", "taking", "stuff", "simple", "east", "hart"))
Q1Srestidy<-unnest_tokens(Q1Omit, word, Experience_Type)
Q1Sres_remove<- anti_join(Q1Srestidy,remove_words) #remove repeat words
Q1Sresclean<-anti_join(Q1Sres_remove, stop_words)
Q1Sres_counts <- Q1Sresclean %>%
rename(original = Q1Sresclean) %>%
group_by(original) %>%
summarise(count = n()) %>%
ungroup() %>% # so we can mutate word
mutate(suggestion = correct_spelling(original)) %>%
filter(suggestion != original)
Q1Sres_counts <- Q1Sresclean %>%
group_by(Q1Sresclean) %>%
summarise(count = n()) %>%
ungroup() %>% # so we can mutate word
mutate(suggestion = correct_spelling(Q1Sresclean)) %>%
filter(suggestion != Q1Sresclean)
Q1Sres_counts <- Q1Sresclean %>%
summarise(count = n()) %>%
ungroup() %>% # so we can mutate word
mutate(suggestion = correct_spelling(Q1Sresclean)) %>%
filter(suggestion != Q1Sresclean)
######################################################################################
#remove words
remove_words <-data.frame("word"= c("coded", "program", "6th", "5th", "3rd", "4th", "7th", "0","1","10","
1st", "27","null", "NA", "na", "coding", "ive", "that's", "code", "grade", "2", "
2015", "2021", "2022", "30", "3rd", "50", "6", "9", "90", "experience", "learned", "called", "candy", "chapman", "forgot", "floor", "lake", "taught", "parents", "taking", "stuff", "simple", "east", "hart"))
Q1Srestidy<-unnest_tokens(Q1Omit, word, Experience_Type, to_lower = FALSE)
Q1Sres_remove<- anti_join(Q1Srestidy,remove_words) #remove repeat words
Q1Sresclean<-anti_join(Q1Sres_remove, stop_words)
Q1Sres_counts <- Q1Sresclean %>%
rename(original = Q1Sresclean) %>%
group_by(original) %>%
summarise(count = n()) %>%
ungroup() %>% # so we can mutate word
mutate(suggestion = correct_spelling(original)) %>%
filter(suggestion != original)
Omit <- as_tibble(Q1Omit, ...)
Omit <- as_tibble(Q1Omit)
##Make correct spelling function
library(hunspell)
library(purrr)
correct_spelling <- function(input) {
output <- case_when(
# any manual corrections
input == 'license' ~ 'licence',
# check and (if required) correct spelling
!hunspell_check(input, dictionary('en_GB')) ~
hunspell_suggest(input, dictionary('en_GB')) %>%
# get first suggestion, or NA if suggestions list is empty
map(1, .default = NA) %>%
unlist(),
TRUE ~ input # if word is correct
)
# if input incorrectly spelled but no suggestions, return input word
ifelse(is.na(output), input, output) }
######################################################################################
#remove words
remove_words <-data.frame("word"= c("coded", "program", "6th", "5th", "3rd", "4th", "7th", "0","1","10","
1st", "27","null", "NA", "na", "coding", "ive", "that's", "code", "grade", "2", "
2015", "2021", "2022", "30", "3rd", "50", "6", "9", "90", "experience", "learned", "called", "candy", "chapman", "forgot", "floor", "lake", "taught", "parents", "taking", "stuff", "simple", "east", "hart"))
Q1Srestidy<-unnest_tokens(Omit, word, Experience_Type, to_lower = FALSE)
Q1Sres_remove<- anti_join(Q1Srestidy,remove_words) #remove repeat words
Q1Sresclean<-anti_join(Q1Sres_remove, stop_words)
Q1Sres_counts <- Q1Sresclean %>%
rename(original = Q1Sresclean) %>%
group_by(original) %>%
summarise(count = n()) %>%
ungroup() %>% # so we can mutate word
mutate(suggestion = correct_spelling(original)) %>%
filter(suggestion != original)
clean <- as_tibble(Q1Sresclean)
Q1Sres_counts <- Q1Sresclean %>%
rename(original = Q1Sresclean) %>%
group_by(original) %>%
summarise(count = n()) %>%
ungroup() %>% # so we can mutate word
mutate(suggestion = correct_spelling(original)) %>%
filter(suggestion != original)
View(Q1Sresclean)
words <- filter(Q1Sresclean,word)
Q1Sres_counts <- words %>%
rename(original = words) %>%
group_by(original) %>%
summarise(count = n()) %>%
ungroup() %>% # so we can mutate word
mutate(suggestion = correct_spelling(original)) %>%
filter(suggestion != original)
words <- filter(Q1Sresclean,word)
Q1Sres_remove<- anti_join(Q1Srestidy,remove_words) #remove repeat words
Q1Sresclean<-anti_join(Q1Sres_remove, stop_words)
words <- filter(Q1Sresclean,word)
words <- filter(Q1Sresclean, "word" )
